---
title: "Roc Callin"
engine: jupyter
---

```{python}

#| echo: false

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal
from sklearn.neighbors import KNeighborsClassifier

# Generate training data
Tr = np.array([[-7, 14], [7, -14]])  # Points chosen so that Euclidean decision boundaries go through (0,0)
Cl = np.array([1, 2])

Nexemplars = Tr.shape[0]
mn, mx = -40, 40
N = 2 * (mx - mn)

# Generate test data
Te = np.array([[mn + j * (mx - mn) / N, mn + i * (mx - mn) / N] 
                for i in range(N + 1) for j in range(N + 1)])

# k-nearest neighbor plots
methods = ['euclidean', 'manhattan']  # Corresponds to 'cityblock' in MATLAB
for m, method in enumerate(methods):
    for k in range(1, Nexemplars):
        plt.figure(figsize=(6, 6))
        plt.axis([mn, mx, mn, mx])
        plt.axis('equal')
        plt.axis('off')
        
        # k-NN classification
        knn = KNeighborsClassifier(n_neighbors=k, metric=method)
        knn.fit(Tr, Cl)
        Lb = knn.predict(Te)
        
        # Plot results
        plt.scatter(Te[:, 0], Te[:, 1], c=Lb, s=3, cmap='coolwarm', alpha=0.5)
        plt.scatter(Tr[:, 0], Tr[:, 1], c=Cl, s=150, edgecolors='k', linewidth=2, cmap='coolwarm')
        
        # Draw decision boundaries for k=1
        if k == 1 and method == 'euclidean':
            circle = plt.Circle((0, 0), np.linalg.norm(Tr[0]), color='m', fill=False)
            plt.gca().add_patch(circle)
        elif k == 1 and method == 'manhattan':
            plt.plot([-21, 21, 21, -21, -21], [21, 21, -21, -21, 21], 'r')
            plt.plot([-21, 21, 21, -21, -21], [21, 21, -21, -21, 21], 'b')
        
        plt.show()

```