---
title: "7.3 Regression"
engine: jupyter
execute: 
    echo: true
code-fold: true
---

```{python}

#| echo: false

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal

n = 100
B = np.array([5, 2, 2])
a, b, c = 5, 2, 2
mu = np.array([5, 5])
cv = -0.99
sigma = np.array([[1, cv], [cv, 1]])
noise = 1

X = np.random.multivariate_normal(mu, sigma, n)
X = np.column_stack((np.ones(n), X))

muX = np.mean(X, axis=0)
XC = X - np.ones((n, 1)) * muX
nCov = XC.T @ XC
nCovD = np.diag(np.diag(nCov))
M = np.outer(muX, muX)
SM = nCov + n * M
SMD = nCovD + n * M

e = np.random.normal(0, noise, n)

y = a + b * X[:, 1] + c * X[:, 2]
ye = y + e

S = X.T @ X
Bhat = np.linalg.inv(S) @ X.T @ ye
BhatD = np.linalg.inv(SMD) @ X.T @ ye

x1 = np.arange(mu[0] - 3, mu[0] + 4, 1)
x2 = np.arange(mu[1] - 3, mu[1] + 4, 1)
z = np.zeros((len(x2), len(x1)))
zhat = np.zeros_like(z)
zhatD = np.zeros_like(z)

for i in range(len(x1)):
    for j in range(len(x2)):
        z[j, i] = a + b * x1[i] + c * x2[j]
        zhat[j, i] = Bhat[0] + Bhat[1] * x1[i] + Bhat[2] * x2[j]
        zhatD[j, i] = BhatD[0] + BhatD[1] * x1[i] + BhatD[2] * x2[j]

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X[:, 1], X[:, 2], ye, color='r', label='Observed')
ax.scatter(X[:, 1], np.full_like(y, mu[1] - 5), ye, color='b')
ax.scatter(np.full_like(y, mu[0] + 5), X[:, 2], ye, color='b')
ax.scatter(X[:, 1], X[:, 2], np.zeros_like(y), color='k')

X1, X2 = np.meshgrid(x1, x2)
ax.plot_surface(X1, X2, zhatD, color='cyan', alpha=0.5)
ax.plot_surface(X1, X2, z, color='gray', alpha=0.5)
ax.view_init(elev=30, azim=45)
plt.show()

```